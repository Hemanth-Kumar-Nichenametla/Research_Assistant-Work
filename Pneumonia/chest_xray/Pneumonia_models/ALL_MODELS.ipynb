{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redisual attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Activation, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the training and validation data\n",
    "train_path = 'chest_xray/train'\n",
    "valid_path = 'chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_attention_block(input_layer, filters):\n",
    "  # First Convolution\n",
    "  conv1 = Conv2D(filters, (3, 3), padding='same')(input_layer)\n",
    "  conv1 = BatchNormalization()(conv1)\n",
    "  conv1 = Activation('relu')(conv1)\n",
    "   \n",
    "  # Second Convolution\n",
    "  conv2 = Conv2D(filters, (3, 3), padding='same')(conv1)\n",
    "  conv2 = BatchNormalization()(conv2)\n",
    "  conv2 = Activation('relu')(conv2)\n",
    "   \n",
    "  # Attention Mechanism\n",
    "  attention = Conv2D(filters, (1, 1), activation='sigmoid', padding='same')(conv2)\n",
    "  scaled = Multiply()([conv2, attention])\n",
    "   \n",
    "  # Residual Connection\n",
    "  residual = Add()([input_layer, scaled])\n",
    "   \n",
    "  return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resatt_model(input_shape, num_classes, learning_rate=0.001):\n",
    "  input_layer = Input(shape=input_shape)\n",
    "\n",
    "  # Initial Convolution\n",
    "  x = Conv2D(64, (7, 7), padding='same', strides=(2, 2))(input_layer)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "   \n",
    "  # Max Pooling\n",
    "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "  # Residual Attention Blocks\n",
    "  for _ in range(3): # You can adjust the number of blocks\n",
    "    x = residual_attention_block(x, 64)\n",
    "   \n",
    "  # Global Average Pooling Layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "  # Output layer\n",
    "  output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=input_layer, outputs=output_layer)\n",
    "  model.compile(\n",
    "    loss='categorical_crossentropy', # Adjust for your problem\n",
    "    optimizer=Adam(learning_rate),\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Multiply, Add\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Create the ResAtt model\n",
    "model = build_resatt_model(IMAGE_SIZE + (3,), num_classes=len(glob('chest_xray/train/*')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 112, 112, 64)         9472      ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 112, 112, 64)         256       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 112, 112, 64)         0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 56, 56, 64)           0         ['activation_19[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 56, 56, 64)           36928     ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 56, 56, 64)           256       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 56, 56, 64)           36928     ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 56, 56, 64)           256       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 56, 56, 64)           4160      ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 56, 56, 64)           0         ['activation_21[0][0]',       \n",
      "                                                                     'conv2d_30[0][0]']           \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 56, 56, 64)           0         ['max_pooling2d_3[0][0]',     \n",
      "                                                                     'multiply_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 56, 56, 64)           36928     ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 56, 56, 64)           256       ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 56, 56, 64)           36928     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 56, 56, 64)           256       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 56, 56, 64)           4160      ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)       (None, 56, 56, 64)           0         ['activation_23[0][0]',       \n",
      "                                                                     'conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 56, 56, 64)           0         ['add_6[0][0]',               \n",
      "                                                                     'multiply_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 56, 56, 64)           36928     ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 56, 56, 64)           256       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 56, 56, 64)           36928     ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 56, 56, 64)           256       ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 56, 56, 64)           0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 56, 56, 64)           4160      ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)       (None, 56, 56, 64)           0         ['activation_25[0][0]',       \n",
      "                                                                     'conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 56, 56, 64)           0         ['add_7[0][0]',               \n",
      "                                                                     'multiply_8[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3  (None, 64)                   0         ['add_8[0][0]']               \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    130       ['global_average_pooling2d_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 245442 (958.76 KB)\n",
      "Trainable params: 244546 (955.26 KB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image data generators for the training and validation data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate training and validation data\n",
    "training_set = train_datagen.flow_from_directory('chest_xray/train',\n",
    "                                                 target_size=IMAGE_SIZE,\n",
    "                                                 batch_size=10,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('chest_xray/test',\n",
    "                                            target_size=IMAGE_SIZE,\n",
    "                                            batch_size=10,\n",
    "                                            class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "522/522 [==============================] - 183s 347ms/step - loss: 0.3233 - accuracy: 0.8545 - val_loss: 2.6269 - val_accuracy: 0.6250\n",
      "Epoch 2/4\n",
      "522/522 [==============================] - 258s 495ms/step - loss: 0.2596 - accuracy: 0.8909 - val_loss: 2.3597 - val_accuracy: 0.6250\n",
      "Epoch 3/4\n",
      "522/522 [==============================] - 8362s 16s/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 6.8861 - val_accuracy: 0.3878\n",
      "Epoch 4/4\n",
      "522/522 [==============================] - 188s 360ms/step - loss: 0.2082 - accuracy: 0.9197 - val_loss: 0.6236 - val_accuracy: 0.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x151a64b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=4,  # You can adjust the number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squeezenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the training and validation data\n",
    "train_path = 'chest_xray/train'\n",
    "valid_path = 'chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 2  # Replace with the actual number of classes in your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom SqueezeNet model\n",
    "def custom_squeezenet(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # Define SqueezeNet architecture here\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2), activation='relu')(input_tensor)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Apply Global Average Pooling directly\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom SqueezeNet model\n",
    "model = custom_squeezenet(input_shape=(224, 224, 3), num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'path_to_squeezenet_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the pre-trained weights (you need to specify the correct weights file)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39mpath_to_squeezenet_weights.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'path_to_squeezenet_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained weights (you need to specify the correct weights file)\n",
    "model.load_weights('path_to_squeezenet_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size\n",
    "IMAGE_SIZE = [331, 331]  # PNASNetLarge input size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the training and validation data\n",
    "train_path = 'chest_xray/train'\n",
    "valid_path = 'chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m-> 1458\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[1;32m   1459\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    518\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    519\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    520\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    521\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    522\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    523\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    524\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1109\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1379\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1380\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb Cell 32\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the PNASNetLarge model from TensorFlow Hub\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pnasnet_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/google/imagenet/pnasnet_large/classification/5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hemu/Desktop/Updated_work_on_Deep_Learning/Research_work_on_Deep_Learning/Pneumonia/chest_xray/Pneumonia_models/ALL_MODELS.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pnasnet \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(pnasnet_url, trainable\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[1;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[0;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[39m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m       set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/module_v2.py:93\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     92\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected a string, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m handle)\n\u001b[0;32m---> 93\u001b[0m module_path \u001b[39m=\u001b[39m resolve(handle)\n\u001b[1;32m     94\u001b[0m is_hub_module_v1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\n\u001b[1;32m     95\u001b[0m     native_module\u001b[39m.\u001b[39mget_module_proto_path(module_path))\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m is_hub_module_v1:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/module_v2.py:48\u001b[0m, in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(handle):\n\u001b[1;32m     25\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m    A string representing the Module path.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mresolver(handle)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/registry.py:49\u001b[0m, in \u001b[0;36mMultiImplRegister.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m impl \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impls):\n\u001b[1;32m     48\u001b[0m   \u001b[39mif\u001b[39;00m impl\u001b[39m.\u001b[39mis_supported(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     50\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     fails\u001b[39m.\u001b[39mappend(\u001b[39mtype\u001b[39m(impl)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/compressed_module_resolver.py:81\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m     77\u001b[0m   response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_urlopen(request)\n\u001b[1;32m     78\u001b[0m   \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39mDownloadManager(handle)\u001b[39m.\u001b[39mdownload_and_uncompress(\n\u001b[1;32m     79\u001b[0m       response, tmp_dir)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39;49matomic_download(handle, download, module_dir,\n\u001b[1;32m     82\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lock_file_timeout_sec())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/resolver.py:421\u001b[0m, in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    419\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading TF-Hub Module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, handle)\n\u001b[1;32m    420\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mMakeDirs(tmp_dir)\n\u001b[0;32m--> 421\u001b[0m download_fn(handle, tmp_dir)\n\u001b[1;32m    422\u001b[0m \u001b[39m# Write module descriptor to capture information about which module was\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m# downloaded by whom and when. The file stored at the same level as a\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m# directory in order to keep the content of the 'model_dir' exactly as it\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m# module caching protocol and no code in the TF-Hub library reads its\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m# content.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m _write_module_descriptor_file(handle, module_dir)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/compressed_module_resolver.py:77\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__.<locals>.download\u001b[0;34m(handle, tmp_dir)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39mDownloadManager(handle)\u001b[39m.\u001b[39mdownload_and_uncompress(\n\u001b[1;32m     72\u001b[0m       response, tmp_dir\n\u001b[1;32m     73\u001b[0m   )\n\u001b[1;32m     75\u001b[0m request \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_compressed_format_query(handle))\n\u001b[0;32m---> 77\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_urlopen(request)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39mDownloadManager(handle)\u001b[39m.\u001b[39mdownload_and_uncompress(\n\u001b[1;32m     79\u001b[0m     response, tmp_dir)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/resolver.py:528\u001b[0m, in \u001b[0;36mHttpResolverBase._call_urlopen\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    526\u001b[0m   \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(request)\n\u001b[1;32m    527\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 528\u001b[0m   \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(request, context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>"
     ]
    }
   ],
   "source": [
    "# Load the PNASNetLarge model from TensorFlow Hub\n",
    "pnasnet_url = \"https://tfhub.dev/google/imagenet/pnasnet_large/classification/5\"\n",
    "pnasnet = hub.KerasLayer(pnasnet_url, trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade certifi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the training and validation data\n",
    "train_path = 'chest_xray/train'\n",
    "valid_path = 'chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
